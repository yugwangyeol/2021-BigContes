{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 전 과정\n",
    " - 세번째 파이프 라인은 앞서 도출한 훈련데이터로 모델을 학습, 튜닝, 앙상블시켜 최종 제출결과물을 뽑아내는 '모델링 전 과정'입니다.\n",
    "    \n",
    "         - 1. 먼저 단일 모델별 기본 성능을 살펴보았습니다.  \n",
    "         - 2. 모델들을 랜덤서치를 이용하여 튜닝하였습니다.\n",
    "         - 3. 앙상블에 사용할 튜닝된 모델들의 모든 조합에 대해서 VotingRegressor를 사용하여 좋은 성능을 내었습니다.\n",
    "         - 이렇게 크게 3가지 과정을 거쳐서 최종 서브미션을 생성해 내었습니다.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "#pd.set_option('max_columns', 100, 'max_rows', 20)\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# OS\n",
    "import os\n",
    "import time\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import KFold\n",
    "n_splits=5; seed = 42\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Ensemble\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "\n",
    "# Saving\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (2891, 72)\n",
      "test shape: (160, 72)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>유역평균강수</th>\n",
       "      <th>강우(A지역)</th>\n",
       "      <th>강우(B지역)</th>\n",
       "      <th>강우(C지역)</th>\n",
       "      <th>강우(D지역)</th>\n",
       "      <th>수위(E지역)</th>\n",
       "      <th>수위(D지역)</th>\n",
       "      <th>유역평균강수.1</th>\n",
       "      <th>강우(A지역).1</th>\n",
       "      <th>강우(B지역).1</th>\n",
       "      <th>...</th>\n",
       "      <th>저수량(예년)</th>\n",
       "      <th>방수로수위</th>\n",
       "      <th>강우량_해당시간</th>\n",
       "      <th>자체유입</th>\n",
       "      <th>총방류량</th>\n",
       "      <th>강우_0집단</th>\n",
       "      <th>강우_1집단</th>\n",
       "      <th>강우_2집단</th>\n",
       "      <th>강우_3집단</th>\n",
       "      <th>수위_0집단</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>122.56875</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.9</td>\n",
       "      <td>66.74</td>\n",
       "      <td>0.4</td>\n",
       "      <td>143.889</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>122.56250</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.9</td>\n",
       "      <td>69.94</td>\n",
       "      <td>0.9</td>\n",
       "      <td>129.754</td>\n",
       "      <td>560.87</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>122.55625</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.9</td>\n",
       "      <td>70.03</td>\n",
       "      <td>0.9</td>\n",
       "      <td>97.138</td>\n",
       "      <td>671.58</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>122.55625</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.9</td>\n",
       "      <td>70.13</td>\n",
       "      <td>3.1</td>\n",
       "      <td>268.040</td>\n",
       "      <td>698.04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>122.55625</td>\n",
       "      <td>11.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.9</td>\n",
       "      <td>70.13</td>\n",
       "      <td>3.1</td>\n",
       "      <td>416.401</td>\n",
       "      <td>703.07</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   유역평균강수  강우(A지역)  강우(B지역)  강우(C지역)  강우(D지역)  수위(E지역)    수위(D지역)  유역평균강수.1  \\\n",
       "0     6.4      7.0      7.0      7.0      8.0     2.54  122.56875       6.3   \n",
       "1     6.3      7.0      8.0      7.0      8.0     2.53  122.56250       6.4   \n",
       "2     6.4      7.0      9.0      7.0      8.0     2.53  122.55625       7.3   \n",
       "3     7.3      7.0     10.0      7.0      8.0     2.53  122.55625       8.2   \n",
       "4     8.2      7.0     12.0      8.0     10.0     2.53  122.55625      11.3   \n",
       "\n",
       "   강우(A지역).1  강우(B지역).1  ...  저수량(예년)  방수로수위  강우량_해당시간     자체유입    총방류량  \\\n",
       "0        7.0        7.0  ...   1093.9  66.74       0.4  143.889    0.00   \n",
       "1        7.0        8.0  ...   1093.9  69.94       0.9  129.754  560.87   \n",
       "2        7.0        9.0  ...   1093.9  70.03       0.9   97.138  671.58   \n",
       "3        7.0       10.0  ...   1093.9  70.13       3.1  268.040  698.04   \n",
       "4        9.0       12.0  ...   1093.9  70.13       3.1  416.401  703.07   \n",
       "\n",
       "      강우_0집단  강우_1집단     강우_2집단     강우_3집단  수위_0집단  \n",
       "0   7.000000     7.0   7.500000   8.000000    2.54  \n",
       "1   7.000000     8.0   8.500000   9.000000    2.53  \n",
       "2   7.000000     9.0   8.666667   9.500000    2.53  \n",
       "3   8.000000    10.0  11.666667  11.333333    2.53  \n",
       "4  10.166667    12.0  13.666667  13.166667    2.53  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/extra_select_train.csv').values\n",
    "test = pd.read_csv('./data/extra_select_test.csv').values\n",
    "target = pd.read_csv('./data/target.csv').values\n",
    "\n",
    "print('train shape:', train.shape)\n",
    "print('test shape:', test.shape)\n",
    "\n",
    "pd.read_csv('./data/extra_select_train.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 단일 모델 기본 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor 모델의 평균 RMSE: 450.350\n",
      "ExtraTreesRegressor 모델의 평균 RMSE: 211.593\n",
      "GradientBoostingRegressor 모델의 평균 RMSE: 263.952\n",
      "XGBRegressor 모델의 평균 RMSE: 246.192\n",
      "LGBMRegressor 모델의 평균 RMSE: 257.305\n",
      "CatBoostRegressor 모델의 평균 RMSE: 173.764\n"
     ]
    }
   ],
   "source": [
    "# 단일모델 정의\n",
    "knn_reg = KNeighborsRegressor(n_jobs=-1)\n",
    "extra_reg = ExtraTreesRegressor(random_state=seed, n_jobs=-1)\n",
    "gbm_reg = GradientBoostingRegressor(random_state=seed)\n",
    "xgb_reg = XGBRegressor(random_state=seed, n_jobs=-1)\n",
    "lgb_reg = LGBMRegressor(random_state=seed, n_jobs=-1)\n",
    "cat_reg = CatBoostRegressor(random_state=seed, verbose=False)\n",
    "\n",
    "regs = [knn_reg, extra_reg, gbm_reg, xgb_reg, lgb_reg, cat_reg]\n",
    "\n",
    "\n",
    "# Cross_val_score 함수정의\n",
    "def get_model_cv_prediction(model, feature_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, feature_data, y_target, scoring='neg_mean_squared_error', cv=kfold, n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print(f'{model.__class__.__name__} 모델의 평균 RMSE: {avg_rmse:.3f}')\n",
    "\n",
    "\n",
    "# 단일 모델별 평균 성능 출력\n",
    "for reg in regs:\n",
    "    get_model_cv_prediction(reg, train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 랜덤서치를 활용한 모델 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor            mean_rmse: 378.961, takes 0.6 secs\n",
      "ExtraTreesRegressor            mean_rmse: 212.808, takes 72.3 secs\n",
      "GradientBoostingRegressor      mean_rmse: 184.889, takes 430.7 secs\n",
      "XGBRegressor                   mean_rmse: 177.448, takes 84.0 secs\n",
      "LGBMRegressor                  mean_rmse: 171.787, takes 48.7 secs\n",
      "CatBoostRegressor              mean_rmse: 159.890, takes 4193.1 secs\n"
     ]
    }
   ],
   "source": [
    "regs = [\n",
    "    (\n",
    "        KNeighborsRegressor(),              \n",
    "        {'n_neighbors': [3,5,7,9,11],        \n",
    "         'weights': ['uniform','distance']}\n",
    "    ),\n",
    "    (\n",
    "        ExtraTreesRegressor(),\n",
    "        {'n_estimators': [100, 150, 200, 250, 300],\n",
    "         'max_depth': [10, 12, 15, 17, 20],\n",
    "         'max_features': [0.8, 0.85, 0.9, 0.95],\n",
    "         'min_samples_split': [1, 2, 3, 4, 5],\n",
    "         'min_samples_leaf': [1, 2, 3, 4, 5]}\n",
    "    ),\n",
    "    (\n",
    "        GradientBoostingRegressor(),\n",
    "        {\n",
    "         'n_estimators': [100,300,500,1000],\n",
    "         'learning_rate': [0.01,0.03,0.05,0.1],\n",
    "         'max_depth': [3,5,6],\n",
    "         'min_samples_leaf' : [3,5,7,9,10],\n",
    "         'min_samples_split' : [2,4,6,8,10],\n",
    "         'subsample' : [0.8,0.9,0.95,1]\n",
    "         }\n",
    "    ),\n",
    "    (\n",
    "        XGBRegressor(),\n",
    "        {\n",
    "        'n_estimators' :[100,200,300,400,500], # kaggle competition에서 best = 1000 \n",
    "        'learning_rate': [0.01,0.03,0.05,0.1],\n",
    "         'max_depth': [3,5,6],\n",
    "         'colsample_bytree' :[0,0.1,0.3,0.5,0.7,0.9,1],\n",
    "         'min_child_weight' :[1,3,5,6],\n",
    "         'subsample' :[0.8,0.9,0.95,1],\n",
    "         'objective' : ['reg:squarederror']\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        LGBMRegressor(),\n",
    "        {'n_estimators': [300,500,700,1000,1100],\n",
    "         'learning_rate': [0.01,0.03,0.05,0.1],\n",
    "         'max_depth': [3,5,7,9,10],\n",
    "         #'boosting' : ['gbrt','dart'],\n",
    "         'colsample_bytree' : [0,0.1,0.3,0.5,0.7,0.9,1],\n",
    "         'subsample' :[0.8,0.9,0.95,1],\n",
    "         'num_leaves' :[30,31,33,35,39,40]\n",
    "         #'feature_fraction' : [0.1,0.3,0.5,0.7,0.9]\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        CatBoostRegressor(),\n",
    "        {'learning_rate': [0.05, 0.1, 0.2, 1, 1.5],\n",
    "         'depth': [3, 5, 7, 9, 10],\n",
    "         'iterations' : [500, 700, 1000, 1200],\n",
    "         'l2_leaf_reg' : [2, 5, 7, 10, 20],\n",
    "         'verbose':[False]}\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "RS_tuned_regs = []  # 튜닝된 모델을 저장\n",
    "for reg, param_grid in regs:\n",
    "    start = time.time()\n",
    "    rand_search = RandomizedSearchCV(reg, param_grid, n_iter=20, scoring='neg_mean_squared_error', \n",
    "                                     cv=kfold, random_state=seed, n_jobs=-1)\n",
    "    rand_search.fit(train, target)\n",
    "    reg_name = reg.__class__.__name__\n",
    "    reg_score = np.sqrt(-rand_search.best_score_) \n",
    "    print(f'{reg_name:30s} mean_rmse: {reg_score:.3f}, takes {time.time() - start:.1f} secs')\n",
    "    RS_tuned_regs.append((reg_name, rand_search.best_estimator_, reg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KNeighborsRegressor',\n",
       "  KNeighborsRegressor(n_neighbors=3, weights='distance'),\n",
       "  378.96128127016635),\n",
       " ('ExtraTreesRegressor',\n",
       "  ExtraTreesRegressor(max_depth=15, max_features=0.85),\n",
       "  212.80782526155588),\n",
       " ('GradientBoostingRegressor',\n",
       "  GradientBoostingRegressor(min_samples_leaf=7, n_estimators=1000, subsample=0.8),\n",
       "  184.888704060011),\n",
       " ('XGBRegressor',\n",
       "  XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=400, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "               tree_method=None, validate_parameters=False, verbosity=None),\n",
       "  177.44764958091315),\n",
       " ('LGBMRegressor',\n",
       "  LGBMRegressor(colsample_bytree=0.1, max_depth=5, n_estimators=1100,\n",
       "                num_leaves=33, subsample=0.95),\n",
       "  171.78664760547025),\n",
       " ('CatBoostRegressor',\n",
       "  <catboost.core.CatBoostRegressor at 0x1630f0c0bc8>,\n",
       "  159.8903020254641)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 튜닝된 모델들의 결과\n",
    "RS_tuned_regs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 튜닝된 모델들 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/RS_tuned_regs_2021-09-15_Final.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "nowDate = now.strftime('%Y-%m-%d')\n",
    "joblib.dump(RS_tuned_regs,f'./models/RS_tuned_regs_{nowDate}_Final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:1040: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[21:47:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:749: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "[21:47:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:438: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 튜닝된 모델들 로드\n",
    "RS_tuned_regs = joblib.load('./models/RS_tuned_regs_2021-09-15_Final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 튜닝된 모델들로 Voting 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 함수 정의\n",
    "def return_fitted_model(model, train, target):\n",
    "    rmse_scores = []\n",
    "    for iter_count, (train_idx, valid_idx) in enumerate(kfold.split(train, target)):\n",
    "\n",
    "        X_train, X_valid = train[train_idx], train[valid_idx]\n",
    "        y_train, y_valid = target[train_idx], target[valid_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_valid)\n",
    "        rmse_score = np.sqrt(mean_squared_error(y_valid, pred))\n",
    "        rmse_scores.append(rmse_score)\n",
    "    return model, np.mean(rmse_scores)\n",
    "\n",
    "# ex: extra_reg, extra_reg_score = return_fitted_model(extra_reg, train, target)\n",
    "# print(f'모델의 평균 성능:  {extra_reg_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 튜닝된 모델들 중 성능이 비슷하고 좋은 4개의 모델에 대해서 앙상블을 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_reg = [\n",
    "    #'KNeighborsRegressor', \n",
    "    #'ExtraTreesRegressor',\n",
    "    'CatBoostRegressor', \n",
    "    'GradientBoostingRegressor', \n",
    "    'XGBRegressor',\n",
    "    'LGBMRegressor'\n",
    "]\n",
    "models_for_ensemble = [(reg[0], reg[1]) for reg in RS_tuned_regs if reg[0] in selected_reg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 모든 조합에 대해서 앙상블을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor●XGBRegressor: 170.492\n",
      "GradientBoostingRegressor●LGBMRegressor: 160.247\n",
      "GradientBoostingRegressor●CatBoostRegressor: 159.566\n",
      "XGBRegressor●LGBMRegressor: 154.449\n",
      "XGBRegressor●CatBoostRegressor: 151.652\n",
      "LGBMRegressor●CatBoostRegressor: 149.236\n",
      "GradientBoostingRegressor●XGBRegressor●LGBMRegressor: 151.671\n",
      "GradientBoostingRegressor●XGBRegressor●CatBoostRegressor: 155.294\n",
      "GradientBoostingRegressor●LGBMRegressor●CatBoostRegressor: 144.646\n",
      "XGBRegressor●LGBMRegressor●CatBoostRegressor: 144.082\n"
     ]
    }
   ],
   "source": [
    "# 3개의 모델 중 2개씩 averaging, 3개씩 averging 모두 해보기\n",
    "start = time.time()\n",
    "best_avg_score = np.inf\n",
    "for model_nums in range(2, len(models_for_ensemble ) + 1):\n",
    "    for avg_estimator in (combinations(models_for_ensemble , model_nums)):\n",
    "        avg_reg = VotingRegressor(estimators = avg_estimator, n_jobs=-1)\n",
    "        avg_model, avg_score = return_fitted_model(avg_reg, train, target)\n",
    "        print(f'{\"●\".join([reg_name for reg_name, _, in avg_estimator])}: {avg_score:.3f}')\n",
    "        if avg_score < best_avg_score:\n",
    "            best_avg_score = avg_score\n",
    "            best_avg_reg = avg_reg\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 가장 좋은 성능의 모델 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=(('XGBRegressor',\n",
       "                             XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=0.5, gamma=0,\n",
       "                                          gpu_id=-1, importance_type='gain',\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=6, min_child_weight=1,\n",
       "                                          missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=400, n_jobs=20,\n",
       "                                          nu...llel_tree=1, random_state=0,\n",
       "                                          reg_alpha=0, reg_lambda=1,\n",
       "                                          scale_pos_weight=1, subsample=0.8,\n",
       "                                          tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None)),\n",
       "                            ('LGBMRegressor',\n",
       "                             LGBMRegressor(colsample_bytree=0.1, max_depth=5,\n",
       "                                           n_estimators=1100, num_leaves=33,\n",
       "                                           subsample=0.95)),\n",
       "                            ('CatBoostRegressor',\n",
       "                             <catboost.core.CatBoostRegressor object at 0x000001E10445E7C0>)),\n",
       "                n_jobs=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_avg_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 앙상블 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model/Average_Ensemble_2021-09-15_Final.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "nowDate = now.strftime('%Y-%m-%d')\n",
    "joblib.dump(best_avg_reg,f'./models/Average_Ensemble_{nowDate}_Final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 모델 로드\n",
    "best_avg_reg = joblib.load('./models/Average_Ensemble_2021-09-15_Final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 서브미션 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_excel('./data/홍수ZERO_데이터/02_평가데이터/2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_평가데이터_210803.xlsx')\n",
    "sub = sub.drop(sub.index[0]).drop('NO',axis=1)\n",
    "\n",
    "sub['유입량']=  best_avg_reg.predict(test)\n",
    "sub \n",
    "\n",
    "sub.to_csv('2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_평가데이터_210803.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ───────────────── End of Pipeline 3/4  ─────────────────"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
